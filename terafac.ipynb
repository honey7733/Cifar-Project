{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14508109,"sourceType":"datasetVersion","datasetId":9266324}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ===============================\n# CELL 0: GLOBAL SETUP (HIGH ACC)\n# ===============================\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torchvision.datasets import CIFAR10\nfrom torch.utils.data import DataLoader\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", DEVICE)\n\ntorch.backends.cudnn.benchmark = True\n\nDATA_PATH = \"/kaggle/input/cipher\"\n\nBATCH_SIZE = 128\nNUM_WORKERS = 4\n\nEPOCHS_L1 = 15\nEPOCHS_L2 = 20\nEPOCHS_L3 = 15\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T12:32:42.774231Z","iopub.execute_input":"2026-01-16T12:32:42.774577Z","iopub.status.idle":"2026-01-16T12:32:42.780817Z","shell.execute_reply.started":"2026-01-16T12:32:42.774547Z","shell.execute_reply":"2026-01-16T12:32:42.780013Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# ===============================\n# CELL 1: DATA LOADING\n# ===============================\n\ntrain_transform = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914,0.4822,0.4465),\n                         (0.2470,0.2435,0.2616))\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914,0.4822,0.4465),\n                         (0.2470,0.2435,0.2616))\n])\n\ntrain_dataset = CIFAR10(DATA_PATH, train=True, transform=train_transform, download=False)\ntest_dataset  = CIFAR10(DATA_PATH, train=False, transform=test_transform, download=False)\n\ntrain_loader = DataLoader(\n    train_dataset, BATCH_SIZE, shuffle=True,\n    num_workers=NUM_WORKERS, pin_memory=True\n)\n\ntest_loader = DataLoader(\n    test_dataset, BATCH_SIZE, shuffle=False,\n    num_workers=NUM_WORKERS, pin_memory=True\n)\n\nprint(\"Train:\", len(train_dataset), \"Test:\", len(test_dataset))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T12:32:59.157797Z","iopub.execute_input":"2026-01-16T12:32:59.158524Z","iopub.status.idle":"2026-01-16T12:33:00.096948Z","shell.execute_reply.started":"2026-01-16T12:32:59.158490Z","shell.execute_reply":"2026-01-16T12:33:00.096309Z"}},"outputs":[{"name":"stdout","text":"Train: 50000 Test: 10000\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# ===============================\n# CELL 2: LEVEL 1 - BASELINE\n# ===============================\n\nmodel = models.resnet50(weights=\"IMAGENET1K_V1\")\nmodel.fc = nn.Linear(model.fc.in_features, 10)\nmodel = model.to(DEVICE)\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\noptimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_L1)\n\nfor epoch in range(EPOCHS_L1):\n    model.train()\n    correct = 0\n\n    for x, y in train_loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        optimizer.zero_grad()\n        loss = criterion(model(x), y)\n        loss.backward()\n        optimizer.step()\n        correct += (model(x).argmax(1) == y).sum().item()\n\n    scheduler.step()\n    print(f\"Epoch {epoch+1} Acc:\", 100*correct/len(train_dataset))\n\n# Test\nmodel.eval()\ncorrect = 0\nwith torch.no_grad():\n    for x, y in test_loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        correct += (model(x).argmax(1) == y).sum().item()\n\nlevel1_acc = 100 * correct / len(test_dataset)\nprint(\"LEVEL 1 ACC:\", level1_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T12:33:11.445647Z","iopub.execute_input":"2026-01-16T12:33:11.446354Z","iopub.status.idle":"2026-01-16T12:39:47.721989Z","shell.execute_reply.started":"2026-01-16T12:33:11.446325Z","shell.execute_reply":"2026-01-16T12:39:47.721191Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 Acc: 70.064\nEpoch 2 Acc: 77.156\nEpoch 3 Acc: 79.87\nEpoch 4 Acc: 81.646\nEpoch 5 Acc: 82.882\nEpoch 6 Acc: 83.64\nEpoch 7 Acc: 84.3\nEpoch 8 Acc: 84.618\nEpoch 9 Acc: 85.476\nEpoch 10 Acc: 86.11\nEpoch 11 Acc: 86.322\nEpoch 12 Acc: 86.454\nEpoch 13 Acc: 86.796\nEpoch 14 Acc: 86.734\nEpoch 15 Acc: 86.832\nLEVEL 1 ACC: 89.48\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# ===============================\n# CELL 3: LEVEL 2 - IMPROVED\n# ===============================\n\nmodel2 = models.resnet18(weights=\"IMAGENET1K_V1\")\nmodel2.fc = nn.Linear(model2.fc.in_features, 10)\nmodel2 = model2.to(DEVICE)\n\noptimizer = optim.AdamW(model2.parameters(), lr=3e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_L2)\n\nfor epoch in range(EPOCHS_L2):\n    model2.train()\n    for x, y in train_loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        optimizer.zero_grad()\n        loss = criterion(model2(x), y)\n        loss.backward()\n        optimizer.step()\n    scheduler.step()\n\n# Test\nmodel2.eval()\ncorrect = 0\nwith torch.no_grad():\n    for x, y in test_loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        correct += (model2(x).argmax(1) == y).sum().item()\n\nlevel2_acc = 100 * correct / len(test_dataset)\nprint(\"LEVEL 2 ACC:\", level2_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T12:40:18.174298Z","iopub.execute_input":"2026-01-16T12:40:18.175040Z","iopub.status.idle":"2026-01-16T12:45:44.943441Z","shell.execute_reply.started":"2026-01-16T12:40:18.175004Z","shell.execute_reply":"2026-01-16T12:45:44.942630Z"}},"outputs":[{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44.7M/44.7M [00:00<00:00, 188MB/s] \n","output_type":"stream"},{"name":"stdout","text":"LEVEL 2 ACC: 87.26\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# ===============================\n# CELL 4: LEVEL 3 - EFFICIENTNET\n# ===============================\n\nmodel3 = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\nmodel3.classifier[1] = nn.Linear(model3.classifier[1].in_features, 10)\nmodel3 = model3.to(DEVICE)\n\noptimizer = optim.AdamW(model3.parameters(), lr=3e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_L3)\n\nfor epoch in range(EPOCHS_L3):\n    model3.train()\n    for x, y in train_loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        optimizer.zero_grad()\n        loss = criterion(model3(x), y)\n        loss.backward()\n        optimizer.step()\n    scheduler.step()\n\n# Test\nmodel3.eval()\ncorrect = 0\nwith torch.no_grad():\n    for x, y in test_loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        correct += (model3(x).argmax(1) == y).sum().item()\n\nlevel3_acc = 100 * correct / len(test_dataset)\nprint(\"LEVEL 3 ACC:\", level3_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T12:46:12.998773Z","iopub.execute_input":"2026-01-16T12:46:12.999345Z","iopub.status.idle":"2026-01-16T12:51:29.710556Z","shell.execute_reply.started":"2026-01-16T12:46:12.999311Z","shell.execute_reply":"2026-01-16T12:51:29.709795Z"}},"outputs":[{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20.5M/20.5M [00:00<00:00, 145MB/s]\n","output_type":"stream"},{"name":"stdout","text":"LEVEL 3 ACC: 84.02\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# ===============================\n# CELL 5: LEVEL 4 - ENSEMBLE\n# ===============================\n\nmodels_list = [model, model2, model3]\nfor m in models_list:\n    m.eval()\n\ncorrect = 0\nwith torch.no_grad():\n    for x, y in test_loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        preds = torch.stack([m(x).softmax(1) for m in models_list]).mean(0)\n        correct += (preds.argmax(1) == y).sum().item()\n\nensemble_acc = 100 * correct / len(test_dataset)\nprint(\" ENSEMBLE ACCURACY:\", ensemble_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T12:51:53.694281Z","iopub.execute_input":"2026-01-16T12:51:53.694562Z","iopub.status.idle":"2026-01-16T12:51:56.232277Z","shell.execute_reply.started":"2026-01-16T12:51:53.694536Z","shell.execute_reply":"2026-01-16T12:51:56.231620Z"}},"outputs":[{"name":"stdout","text":" ENSEMBLE ACCURACY: 90.1\n","output_type":"stream"}],"execution_count":22}]}